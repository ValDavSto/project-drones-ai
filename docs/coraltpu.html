<!DOCTYPE html SYSTEM "about:legacy-compat">
<html lang="en-US" data-preset="contrast" data-primary-color="#307FFF"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="UTF-8"><meta name="robots" content="noindex"><meta name="built-on" content="2025-07-09T22:42:34.1358869"><title>AI Hardware | Drone Project</title><script type="application/json" id="virtual-toc-data">[{"id":"installation","level":0,"title":"Installation","anchor":"#installation"},{"id":"python-api","level":0,"title":"Python API","anchor":"#python-api"},{"id":"integration-test","level":0,"title":"Integration Test","anchor":"#integration-test"}]</script><script type="application/json" id="topic-shortcuts"></script><link href="https://resources.jetbrains.com/writerside/apidoc/6.22.0-b776/app.css" rel="stylesheet"><meta name="msapplication-TileColor" content="#000000"><link rel="apple-touch-icon" sizes="180x180" href="https://jetbrains.com/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="https://jetbrains.com/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="https://jetbrains.com/favicon-16x16.png"><meta name="msapplication-TileImage" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-144x144.png"><meta name="msapplication-square70x70logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-70x70.png"><meta name="msapplication-square150x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-150x150.png"><meta name="msapplication-wide310x150logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x150.png"><meta name="msapplication-square310x310logo" content="https://resources.jetbrains.com/storage/ui/favicons/mstile-310x310.png"><meta name="image" content=""><!-- Open Graph --><meta property="og:title" content="AI Hardware | Drone Project"><meta property="og:description" content=""><meta property="og:image" content=""><meta property="og:site_name" content="Drone Project Help"><meta property="og:type" content="website"><meta property="og:locale" content="en_US"><meta property="og:url" content="writerside-documentation/coraltpu.html"><!-- End Open Graph --><!-- Twitter Card --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content=""><meta name="twitter:title" content="AI Hardware | Drone Project"><meta name="twitter:description" content=""><meta name="twitter:creator" content=""><meta name="twitter:image:src" content=""><!-- End Twitter Card --><!-- Schema.org WebPage --><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "WebPage",
    "@id": "writerside-documentation/coraltpu.html#webpage",
    "url": "writerside-documentation/coraltpu.html",
    "name": "AI Hardware | Drone Project",
    "description": "",
    "image": "",
    "inLanguage":"en-US"
}</script><!-- End Schema.org --><!-- Schema.org WebSite --><script type="application/ld+json">{
    "@type": "WebSite",
    "@id": "writerside-documentation/#website",
    "url": "writerside-documentation/",
    "name": "Drone Project Help"
}</script><!-- End Schema.org --></head><body data-id="CoralTPU" data-main-title="AI Hardware" data-article-props="{&quot;seeAlsoStyle&quot;:&quot;links&quot;}" data-template="article" data-breadcrumbs=""><div class="wrapper"><main class="panel _main"><header class="panel__header"><div class="container"><h3>Drone Project  Help</h3><div class="panel-trigger"></div></div></header><section class="panel__content"><div class="container"><article class="article" data-shortcut-switcher="inactive"><h1 data-toc="CoralTPU" id="CoralTPU.md">AI Hardware</h1><p id="h1eays_3">Deploying real-time object detection on a drone with on-board processing presents unique challenges due to constraints in size, weight, power consumption, and processing capability. The hardware package must be able to receive video frames at a reasonable frame rate, process them in real-time, and optimally send the results back to the drone's control system.</p><p id="h1eays_4">For our purposes, we are using a <code class="code" id="h1eays_11">2.5-inch</code> <code class="code" id="h1eays_12">FlyFish Velociraptor</code> drone frame, which is already quite compact and has no dedicated space for additional hardware besides flight related components. As the usage of larger single-board computers (SBCs) is not feasible due to space constraints, our choice fell on the 32-bit <code class="code" id="h1eays_13">Raspberry Pi Zero W 1.1</code>. Why not the later revision <code class="code" id="h1eays_14">Raspberry Pi Zero W 2</code> with 64-bit support? Well, we didn't have any in stock. - Update: We got our hands on a <code class="code" id="h1eays_15">Raspberry Pi Zero W 2</code>, so we are using this instead.</p><p id="h1eays_5">However, a single-board computer of this size, especially the Pi Zero, is limited in computational power. This makes it insufficient for running complex machine learning models, particularly those required for real-time object detection using camera input.</p><p id="h1eays_6">The <code class="code" id="h1eays_16">Coral Edge TPU</code> (Tensor Processing Unit) is specifically designed to execute deep learning models efficiently, enabling high-speed inference with significantly lower power consumption compared to CPU-based processing. When paired with a Raspberry Pi, it offloads the heavy lifting of running TensorFlow Lite models. The model we are using, the <a href="https://coral.ai/products/accelerator" id="h1eays_17" data-external="true" rel="noopener noreferrer" target="_blank"><code class="code" id="h1eays_19">Coral USB Accelerator</code></a>, is connected via <code class="code" id="h1eays_18">USB 2.0</code>.</p><p id="h1eays_7">While being a generic USB device, the Coral TPU requires proper drivers for the Raspberry Pi to function correctly.</p><section class="chapter"><h2 id="installation" data-toc="installation">Installation</h2><p id="h1eays_20">The <code class="code" id="h1eays_26">Edge TPU Runtime</code> is not included in the standard Raspberry Pi OS image, nor the standard debian <code class="code" id="h1eays_27">APT</code> package manager repository. Thus, we need to install it manually:</p><div class="code-block" data-lang="bash">
# Add repository to the APT sources list
echo &quot;deb https://packages.cloud.google.com/apt coral-edgetpu-stable main&quot; | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list
# Add the GPG key
curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
# Update the package list
sudo apt-get update
</div><p id="h1eays_22">Afterwards, the <code class="code" id="h1eays_28">Edge TPU Runtime</code> can be installed with the following command:</p><div class="code-block" data-lang="bash">
sudo apt-get install libedgetpu1-std
</div><p id="h1eays_24">There is also a <code class="code" id="h1eays_29">libedgetpu1-max</code> package available, which is optimized for maximum performance. But to be honest, we are quite limited by all means of the Raspberry Pi, so we don't need to worry about that.</p><p id="h1eays_25">Installation Guide Source: <a href="https://coral.ai/docs/accelerator/get-started/#1-install-the-edge-tpu-runtime" id="h1eays_30" data-external="true" rel="noopener noreferrer" target="_blank">coral.ai</a></p></section><section class="chapter"><h2 id="python-api" data-toc="python-api">Python API</h2><p id="h1eays_31">For our purpose, we are using the <code class="code" id="h1eays_35">Python</code> programming language. The <code class="code" id="h1eays_36">Coral Edge TPU</code> provides an api for integration with TensorFlow Lite models. With the repository already added, we can install the <code class="code" id="h1eays_37">python3-pycoral</code> package with the following command:</p><div class="code-block" data-lang="bash">
sudo apt-get install python3-pycoral
</div><p id="h1eays_33">The package has additional dependencies such as <code class="code" id="h1eays_38">numpy</code>, which are automatically installed by the package manager. To be fully set up for our poject, we also need to install the OpenCV <code class="code" id="h1eays_39">cv2</code> package for image processing and video handling. This can be done with the following command:</p><div class="code-block" data-lang="bash">
sudo apt-get install python3-opencv
</div></section><section class="chapter"><h2 id="integration-test" data-toc="integration-test">Integration Test</h2><p id="h1eays_40">To test the integration of the <code class="code" id="h1eays_50">Coral Edge TPU</code> with the <code class="code" id="h1eays_51">Raspberry Pi</code>, we can run an example provided by the <code class="code" id="h1eays_52">Google Coral</code> team.</p><div class="code-block" data-lang="bash">
mkdir coral &amp;&amp; cd coral
git clone https://github.com/google-coral/pycoral.git
cd pycoral
</div><p id="h1eays_42">The repository does not come with the finished model files, so we need to download them manually. The <code class="code" id="h1eays_53">Google Coral</code> team provides a set of pre-trained models for the <code class="code" id="h1eays_54">Coral Edge TPU</code>, which can be found <a href="https://coral.ai/models/" id="h1eays_55" data-external="true" rel="noopener noreferrer" target="_blank">here</a>. For this test, we are looking into classification of birds from an image.</p><div class="code-block" data-lang="bash">
bash examples/install_requirements.sh classify_image.py
</div><p id="h1eays_44">Once done, we start the classification test run:</p><div class="code-block" data-lang="bash">
python examples/classify_image.py --model test_data/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite --labels test_data/inat_bird_labels.txt --input test_data/parrot.jpg
</div><p id="h1eays_46">The output should (and fortunately does) look like this:</p><div class="code-block" data-lang="bash">
----INFERENCE TIME----
Note: The first inference on Edge TPU is slow because it includes loading the model into Edge TPU memory.
129.8ms
3.0ms
2.8ms
2.9ms
2.9ms
-------RESULTS--------
Ara macao (Scarlet Macaw): 0.75781
</div><p id="h1eays_48">Our measured initial first inference time of <code class="code" id="h1eays_56">129.8ms</code> is quite high, which is likely caused by us using the <code class="code" id="h1eays_57">USB 2.0</code> interface of the <code class="code" id="h1eays_58">Raspberry Pi Zero</code>, instead of the <code class="code" id="h1eays_59">3.0</code> standard recommended by Coral.</p><p id="h1eays_49">Note: The <code class="code" id="h1eays_60">Coral USB Accelerator</code> has no means of communicating its functionality besides a white LED on the device, where a continuous light means a passive state, while a blinking light indicates an active state. The proper way of knowing if the device is working is by measuring the processing time. If the model was executed on the CPU, the time would be significantly higher.</p></section><div class="last-modified">07 Juli 2025</div><div data-feedback-placeholder="true"></div><div class="navigation-links _bottom"><a href="autostart.html" class="navigation-links__prev">Autostart Using systemd (cloudchasers.service)</a><a href="rotors.html" class="navigation-links__next">Rotors</a></div></article><div id="disqus_thread"></div></div></section></main></div><script src="https://resources.jetbrains.com/writerside/apidoc/6.22.0-b776/app.js"></script></body></html>